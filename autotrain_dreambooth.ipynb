{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAJU009F/GEN-AI-ML/blob/main/autotrain_dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JvMRbVLEJlZT"
      },
      "outputs": [],
      "source": [
        "#@title ðŸ¤— AutoTrain DreamBooth\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload images to a folder named `images/`\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can also select sd2/2.1 or sd1.5\n",
        "#@markdown - update prompt and remember it. choose keywords that don't usually appear in dictionaries\n",
        "#@markdown - add huggingface information (token) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "#@markdown - report issues / feature requests here: https://github.com/huggingface/autotrain-advanced/issues\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "project_name = 'MY-AI-MDL-I' # @param {type:\"string\"}\n",
        "model_name = 'stabilityai/stable-diffusion-xl-base-1.0' # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-2-1\", \"stabilityai/stable-diffusion-2-1-base\"]\n",
        "prompt = 'photo of a sks dog' # @param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"Raj009f\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 1e-4 # @param {type:\"number\"}\n",
        "num_steps = 500 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "gradient_accumulation = 4 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "resolution = 1024 # @param {type:\"slider\", min:128, max:1024, step:128}\n",
        "use_8bit_adam = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "use_xformers = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "train_text_encoder = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "disable_gradient_checkpointing = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PROMPT\"] = prompt\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_STEPS\"] = str(num_steps)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"RESOLUTION\"] = str(resolution)\n",
        "os.environ[\"USE_8BIT_ADAM\"] = str(use_8bit_adam)\n",
        "os.environ[\"USE_XFORMERS\"] = str(use_xformers)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"TRAIN_TEXT_ENCODER\"] = str(train_text_encoder)\n",
        "os.environ[\"DISABLE_GRADIENT_CHECKPOINTING\"] = str(disable_gradient_checkpointing)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "outputId": "3476ea0c-ee20-41c5-91b5-e8b1e19cf143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mRunning DreamBooth Training\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m286\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: train, deploy, config, func, version, log, train_split, valid_split, inference, backend, data_path\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240703_160111821.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_163633928.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240209_151346768.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240204_204525848.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_163625730.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240703_160108887.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240214_231250370.MP~2.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240214_162905904.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_165244555.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_162832763.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240215_003341840.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240209_151345577.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_163629777.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240203_215011379.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_161153717.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240203_215137693~2.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240215_003338239.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240203_215129200.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_163636401.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_165249554.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240214_231240962.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240214_162904845.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240704_163622845.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240703_160057441.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240214_231250370.MP.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSaving concept images\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.preprocessor.dreambooth\u001b[0m:\u001b[36m_save_concept_images\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mimages/PXL_20240204_233900599.jpg\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m523\u001b[0m - \u001b[1m['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'MY-AI-MDL-I/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:43:16\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m524\u001b[0m - \u001b[1m{'model': 'stabilityai/stable-diffusion-xl-base-1.0', 'vae_model': None, 'revision': None, 'tokenizer': None, 'image_path': 'MY-AI-MDL-I/autotrain-data', 'class_image_path': None, 'prompt': 'photo of a sks dog', 'class_prompt': None, 'num_class_images': 100, 'class_labels_conditioning': None, 'prior_preservation': False, 'prior_loss_weight': 1.0, 'project_name': 'MY-AI-MDL-I', 'seed': 42, 'resolution': 1024, 'center_crop': False, 'train_text_encoder': False, 'batch_size': 1, 'sample_batch_size': 4, 'epochs': 1, 'num_steps': 500, 'checkpointing_steps': 100000, 'resume_from_checkpoint': None, 'gradient_accumulation': 4, 'disable_gradient_checkpointing': False, 'lr': 0.0001, 'scale_lr': False, 'scheduler': 'constant', 'warmup_steps': 0, 'num_cycles': 1, 'lr_power': 1.0, 'dataloader_num_workers': 0, 'use_8bit_adam': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'allow_tf32': False, 'prior_generation_precision': None, 'local_rank': -1, 'xformers': False, 'pre_compute_text_embeddings': False, 'tokenizer_max_length': None, 'text_encoder_use_attention_mask': False, 'rank': 4, 'xl': True, 'mixed_precision': 'fp16', 'token': '*****', 'push_to_hub': True, 'username': 'Raj009f', 'validation_prompt': None, 'num_validation_images': 4, 'validation_epochs': 50, 'checkpoints_total_limit': None, 'validation_images': None, 'logging': False}\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-10-26 09:43:19\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[33m\u001b[1mFailed to download dataset: 404 Client Error. (Request ID: Root=1-671cb9b7-7ec43eeb4ee2fb3d1a70d897;e8c3b4e3-45ab-4945-9055-7c3cc6825536)\n",
            "\n",
            "Repository Not Found for url: https://huggingface.co/api/datasets/MY-AI-MDL-I/autotrain-data/revision/main.\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are authenticated.\u001b[0m\n",
            "tokenizer/tokenizer_config.json: 100% 737/737 [00:00<00:00, 4.18MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 6.30MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 2.12MB/s]\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 2.11MB/s]\n",
            "tokenizer_2/tokenizer_config.json: 100% 725/725 [00:00<00:00, 5.25MB/s]\n",
            "tokenizer_2/special_tokens_map.json: 100% 460/460 [00:00<00:00, 4.04MB/s]\n",
            "text_encoder/config.json: 100% 565/565 [00:00<00:00, 4.20MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "text_encoder_2/config.json: 100% 575/575 [00:00<00:00, 3.34MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "model_index.json: 100% 609/609 [00:00<00:00, 4.89MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "scheduler/scheduler_config.json: 100% 479/479 [00:00<00:00, 3.51MB/s]\n",
            "{'thresholding', 'rescale_betas_zero_snr', 'variance_type', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "model.safetensors: 100% 492M/492M [00:02<00:00, 228MB/s]\n",
            "model.safetensors: 100% 2.78G/2.78G [00:12<00:00, 226MB/s]\n",
            "vae/config.json: 100% 642/642 [00:00<00:00, 4.68MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 234MB/s]\n",
            "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
            "unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 12.1MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 10.3G/10.3G [01:15<00:00, 136MB/s] \n",
            "{'reverse_transformer_layers_per_block', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m931\u001b[0m - \u001b[1m***** Running training *****\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m932\u001b[0m - \u001b[1m  Num examples = 26\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m933\u001b[0m - \u001b[1m  Num batches each epoch = 26\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m934\u001b[0m - \u001b[1m  Num Epochs = 72\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m935\u001b[0m - \u001b[1m  Instantaneous batch size per device = 1\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m936\u001b[0m - \u001b[1m  Total train batch size (w. parallel, distributed & accumulation) = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m937\u001b[0m - \u001b[1m  Gradient Accumulation steps = 4\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 09:46:19\u001b[0m | \u001b[36mautotrain.trainers.dreambooth.train_xl\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m938\u001b[0m - \u001b[1m  Total optimization steps = 500\u001b[0m\n",
            "Steps: 100% 500/500 [1:30:17<00:00, 11.03s/it, loss=0.0631, lr=0.0001]Model weights saved in MY-AI-MDL-I/pytorch_lora_weights.safetensors\n",
            "Steps: 100% 500/500 [1:30:17<00:00, 10.83s/it, loss=0.0631, lr=0.0001]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 11:16:36\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mConverting model to Kohya format...\u001b[0m\n",
            "pytorch_lora_weights.safetensors:   0% 0.00/23.4M [00:00<?, ?B/s]\n",
            "Upload 2 LFS files:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0% 16.4k/23.4M [00:00<02:48, 139kB/s]\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:   0% 16.4k/23.5M [00:00<02:51, 137kB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  36% 8.31M/23.4M [00:00<00:00, 35.9MB/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors:  63% 14.6M/23.4M [00:00<00:00, 42.2MB/s]\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors:  33% 7.63M/23.5M [00:00<00:00, 17.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.safetensors:  93% 21.7M/23.4M [00:00<00:00, 24.8MB/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100% 23.4M/23.4M [00:01<00:00, 12.2MB/s]\n",
            "\n",
            "Upload 2 LFS files:  50% 1/2 [00:02<00:02,  2.17s/it]\u001b[A\n",
            "\n",
            "pytorch_lora_weights_kohya.safetensors: 100% 23.5M/23.5M [00:02<00:00, 9.51MB/s]\n",
            "\n",
            "Upload 2 LFS files: 100% 2/2 [00:02<00:00,  1.36s/it]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-10-26 11:16:43\u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m392\u001b[0m - \u001b[1mJob ID: 2904\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain dreambooth \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--image-path images/ \\\n",
        "--prompt \"${PROMPT}\" \\\n",
        "--resolution ${RESOLUTION} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--num-steps ${NUM_STEPS} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "$( [[ \"$USE_XFORMERS\" == \"True\" ]] && echo \"--xformers\" ) \\\n",
        "$( [[ \"$TRAIN_TEXT_ENCODER\" == \"True\" ]] && echo \"--train-text-encoder\" ) \\\n",
        "$( [[ \"$USE_8BIT_ADAM\" == \"True\" ]] && echo \"--use-8bit-adam\" ) \\\n",
        "$( [[ \"$DISABLE_GRADIENT_CHECKPOINTING\" == \"True\" ]] && echo \"--disable_gradient-checkpointing\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LvIS7-7PcLT"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "# this is the inference code that you can use after you have trained your model\n",
        "# Unhide code below and change prj_path to your repo or local path (e.g. my_dreambooth_project)\n",
        "#\n",
        "#\n",
        "#\n",
        "# from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "# import torch\n",
        "\n",
        "# prj_path = \"username/repo_name\"\n",
        "# model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "# pipe = DiffusionPipeline.from_pretrained(\n",
        "#     model,\n",
        "#     torch_dtype=torch.float16,\n",
        "# )\n",
        "# pipe.to(\"cuda\")\n",
        "# pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "# refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "#     \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "#     torch_dtype=torch.float16,\n",
        "# )\n",
        "# refiner.to(\"cuda\")\n",
        "\n",
        "# prompt = \"photo of a sks dog in a bucket\"\n",
        "\n",
        "# seed = 42\n",
        "# generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "# image = pipe(prompt=prompt, generator=generator).images[0]\n",
        "# image = refiner(prompt=prompt, generator=generator, image=image).images[0]\n",
        "# image.save(f\"generated_image.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}